{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079dc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b1a9fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "78ad89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def elman_init(input_size, hidden_size, output_size):\n",
    "    params = {\n",
    "        'w_ih': nn.Parameter(torch.randn(hidden_size, input_size) * 0.01),  # Corrected shape\n",
    "        'w_hh': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_ih': nn.Parameter(torch.zeros(hidden_size)),\n",
    "        'b_hh': nn.Parameter(torch.zeros(hidden_size)),\n",
    "        'w_out': nn.Parameter(torch.randn(output_size, hidden_size) * 0.01),  # Output layer weight\n",
    "        'b_out': nn.Parameter(torch.zeros(output_size)),\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def elman_forward(x, params):\n",
    "    \"\"\"\n",
    "    x: (batch_size, seq_len, input_dim)   # One-hot encoded input (input_dim = 9)\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, input_dim = x.size()  \n",
    "\n",
    "    hidden_size = params['w_hh'].size(0)\n",
    "    h_t = torch.zeros(batch_size, hidden_size, device=x.device)  \n",
    "\n",
    "    for t in range(seq_len):\n",
    "        x_t = x[:, t] \n",
    "        \n",
    "        ih = x_t @ params['w_ih'].T \n",
    "        hh = h_t @ params['w_hh'] \n",
    "        \n",
    "        h_t = torch.tanh(ih + hh + params['b_ih'] + params['b_hh'])  \n",
    "\n",
    "    output = h_t @ params['w_out'].T + params['b_out'] \n",
    "    \n",
    "    return output.view(batch_size, -1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "dab5ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_init(input_size, hidden_size, output_size):\n",
    "   \n",
    "    params = {\n",
    "       \n",
    "        'w_ii': nn.Parameter(torch.randn(input_size, hidden_size) * 0.01),\n",
    "        'w_hi': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_i': nn.Parameter(torch.zeros(hidden_size)),\n",
    "       \n",
    "        'w_if': nn.Parameter(torch.randn(input_size, hidden_size) * 0.01),\n",
    "        'w_hf': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_f': nn.Parameter(torch.ones(hidden_size)),  \n",
    "        \n",
    "       \n",
    "        'w_ig': nn.Parameter(torch.randn(input_size, hidden_size) * 0.01),\n",
    "        'w_hg': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_g': nn.Parameter(torch.zeros(hidden_size)),\n",
    "        \n",
    "        \n",
    "        'w_io': nn.Parameter(torch.randn(input_size, hidden_size) * 0.01),\n",
    "        'w_ho': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_o': nn.Parameter(torch.zeros(hidden_size)),\n",
    "        \n",
    "      \n",
    "        'w_out': nn.Parameter(torch.randn(hidden_size, output_size) * 0.01),\n",
    "        'b_out': nn.Parameter(torch.zeros(output_size)),\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def lstm_forward(x, params):\n",
    "    \"\"\"\n",
    "    x: (batch_size, seq_len, input_dim)\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, input_dim = x.size()\n",
    "    hidden_size = params['w_hi'].size(1) \n",
    "    \n",
    "    h_t = torch.zeros(batch_size, hidden_size, device=x.device)\n",
    "    c_t = torch.zeros(batch_size, hidden_size, device=x.device)\n",
    "    \n",
    "    for t in range(seq_len):\n",
    "        x_t = x[:, t] \n",
    "        \n",
    "        # Input gate \n",
    "        i_t = torch.sigmoid(x_t @ params['w_ii'] + h_t @ params['w_hi'] + params['b_i'])\n",
    "        \n",
    "        # Forget gate\n",
    "        f_t = torch.sigmoid(x_t @ params['w_if'] + h_t @ params['w_hf'] + params['b_f'])\n",
    "        \n",
    "        # Cell update\n",
    "        g_t = torch.tanh(x_t @ params['w_ig'] + h_t @ params['w_hg'] + params['b_g'])\n",
    "        \n",
    "        # Output gate \n",
    "        o_t = torch.sigmoid(x_t @ params['w_io'] + h_t @ params['w_ho'] + params['b_o'])\n",
    "        \n",
    "        # Update cell state\n",
    "        c_t = f_t * c_t + i_t * g_t\n",
    "        \n",
    "        # Update hidden state\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "    \n",
    "    # Final prediction\n",
    "    output = h_t @ params['w_out'] + params['b_out']\n",
    "    return output.view(batch_size, -1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5b3d430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_init(input_size, hidden_size, output_size):\n",
    "    \n",
    "    params = {\n",
    "        # Update gate\n",
    "        'w_iz': nn.Parameter(torch.randn(input_size, hidden_size) * 0.01),\n",
    "        'w_hz': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_z': nn.Parameter(torch.zeros(hidden_size)),\n",
    "        \n",
    "        # Reset gate\n",
    "        'w_ir': nn.Parameter(torch.randn(input_size, hidden_size) * 0.01),\n",
    "        'w_hr': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_r': nn.Parameter(torch.zeros(hidden_size)),\n",
    "        \n",
    "        #  hidden state\n",
    "        'w_in': nn.Parameter(torch.randn(input_size, hidden_size) * 0.01),\n",
    "        'w_hn': nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01),\n",
    "        'b_n': nn.Parameter(torch.zeros(hidden_size)),\n",
    "        \n",
    "        # Output layer\n",
    "        'w_out': nn.Parameter(torch.randn(hidden_size, output_size) * 0.01),\n",
    "        'b_out': nn.Parameter(torch.zeros(output_size)),\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def gru_forward(x, params):\n",
    "   \n",
    "    batch_size, seq_len, input_dim = x.size()\n",
    "    hidden_size = params['w_hz'].size(1)\n",
    "    \n",
    "    h_t = torch.zeros(batch_size, hidden_size, device=x.device)\n",
    "    \n",
    "    for t in range(seq_len):\n",
    "        x_t = x[:, t] \n",
    "        \n",
    "        # Update gate \n",
    "        z_t = torch.sigmoid(x_t @ params['w_iz'] + h_t @ params['w_hz'] + params['b_z'])\n",
    "        \n",
    "        # Reset gate \n",
    "        r_t = torch.sigmoid(x_t @ params['w_ir'] + h_t @ params['w_hr'] + params['b_r'])\n",
    "        \n",
    "        # Hidden state\n",
    "        n_t = torch.tanh(x_t @ params['w_in'] + (r_t * h_t) @ params['w_hn'] + params['b_n'])\n",
    "        \n",
    "        # Update hidden state\n",
    "        h_t = (1 - z_t) * h_t + z_t * n_t\n",
    "    \n",
    "    # Final prediction\n",
    "    output = h_t @ params['w_out'] + params['b_out']\n",
    "    return output.view(batch_size, -1)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e211c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(forward_func, params, train_x, train_y, test_x, test_y, batch_size, epochs, lr):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    optimizer = optim.Adam(params.values(), lr=lr)\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "    num_samples = train_x.shape[0]  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_loss = 0\n",
    "        permutation = torch.randperm(num_samples) \n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            indices = permutation[i:i + batch_size]  \n",
    "            batch_x, batch_y = train_x[indices], train_y[indices]  \n",
    "\n",
    "           \n",
    "            batch_x = batch_x.float() \n",
    "\n",
    "            outputs = forward_func(batch_x, params)\n",
    "            loss = mse_loss(outputs, batch_y) \n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        epoch_train_loss /= (num_samples // batch_size)  \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "       \n",
    "        with torch.no_grad():\n",
    "            test_x = test_x.float()  \n",
    "            test_outputs = forward_func(test_x, params)\n",
    "            test_loss = mse_loss(test_outputs, test_y).item()\n",
    "        \n",
    "        val_losses.append(test_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {epoch_train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses,outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746480ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(train_losses1, train_losses2, train_losses3,base_losses,name):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, train_losses1, label='Train Loss Elman', linestyle='-')\n",
    "    plt.plot(epochs, train_losses2, label='Train Loss GRU', linestyle='-')\n",
    "    plt.plot(epochs, train_losses3, label='Train Loss LSTM', linestyle='-')\n",
    "    plt.plot(epochs, [base_losses] * len(epochs), label='Baseline Loss', linestyle='-')\n",
    "#     plt.axhline(y=1, color='r', linestyle=':', label='y=1')  # Horizontal line at y=1\n",
    "    \n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Training & Test Loss Over Epochs ,{name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d58d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encode_braces(sequence, max_len):\n",
    "    bracket_map = {'(': 0, ')': 1, '{': 2, '}': 3, '[': 4, ']': 5, '<': 6, '>': 7}\n",
    "    vocab_size = len(bracket_map) + 1  \n",
    "\n",
    "    encoded = np.zeros((max_len, vocab_size), dtype=np.float32)\n",
    "    for i, ch in enumerate(sequence[:max_len]):\n",
    "        index = bracket_map.get(ch, 8) \n",
    "        encoded[i][index] = 1.0\n",
    "\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = load_dataset(\"train.json\")\n",
    "test_data = load_dataset(\"test.json\")\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "max_len = max(max(len(item['Sequence']) for item in train_data),\n",
    "              max(len(item['Sequence']) for item in test_data))\n",
    "\n",
    "\n",
    "train_x = torch.tensor([encode_braces(item['Sequence'], max_len) for item in train_data], dtype=torch.float32)\n",
    "train_y = torch.tensor([item['Count'] for item in train_data], dtype=torch.float32)  \n",
    "\n",
    "\n",
    "\n",
    "test_x = torch.tensor([encode_braces(item['Sequence'], max_len) for item in test_data], dtype=torch.float32) \n",
    "test_y = torch.tensor([item['Count'] for item in test_data], dtype=torch.float32)\n",
    "print(train_x.shape)  \n",
    "print(test_x.shape)   \n",
    "print(train_y.shape) \n",
    "print(test_y.shape)  \n",
    "\n",
    "ones_tensor = torch.ones_like(train_y)\n",
    "base_loss = mse_loss(ones_tensor,train_y)\n",
    "print(test_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 9  \n",
    "hidden_size = 8\n",
    "output_size = 1\n",
    "params = elman_init(input_size, hidden_size, output_size)\n",
    "\n",
    "train_losses1, test_losses1,outputs1 = train_model(elman_forward, params, train_x,train_y, test_x,test_y,32,epochs=20, lr=0.001)\n",
    "print(outputs1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 9  \n",
    "hidden_size = 8\n",
    "output_size = 1\n",
    "params = gru_init(input_size, hidden_size, output_size)\n",
    "\n",
    "train_losses2, test_losses2,outputs2 = train_model(gru_forward, params, train_x,train_y, test_x,test_y,32,epochs=20, lr=0.001)\n",
    "print(outputs2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76268afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 9  \n",
    "hidden_size = 8\n",
    "output_size = 1\n",
    "params = lstm_init(input_size, hidden_size, output_size)\n",
    "\n",
    "train_losses3, test_losses3,outputs3 = train_model(lstm_forward, params, train_x,train_y, test_x,test_y,32,epochs=20, lr=0.001)\n",
    "print(outputs3[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses1, train_losses2, train_losses3,base_loss,\"Training Errors\")\n",
    "plot_losses(test_losses1, test_losses2, test_losses3,base_loss,\"Testing Errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99af63a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
